{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP329Fnq1mboAtc3PnRh0Hd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falgunip02/IPD/blob/main/LocationSuggest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "class CropLocationSuggester:\n",
        "    def __init__(self, csv_file):\n",
        "        self.csv_file = csv_file\n",
        "        self.df = None\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def load_data(self):\n",
        "        try:\n",
        "            self.df = pd.read_csv(self.csv_file, names=['croptype', 'labourprice', 'location'])\n",
        "        except FileNotFoundError:\n",
        "            print(\"Error: CSV file not found.\")\n",
        "            return False\n",
        "        except pd.errors.EmptyDataError:\n",
        "            print(\"Error: CSV file is empty.\")\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def prepare_data(self):\n",
        "        if self.df is None:\n",
        "            return False\n",
        "        self.df['croptype'] = self.label_encoder.fit_transform(self.df['croptype'])\n",
        "        self.df['location'] = self.label_encoder.fit_transform(self.df['location'])\n",
        "        return True\n",
        "\n",
        "    def filter_data(self, crop_type):\n",
        "        filtered_data = self.df[self.df['croptype'] == crop_type]\n",
        "        return filtered_data\n",
        "\n",
        "    def train_model(self, X, y):\n",
        "        regressor = RandomForestRegressor()\n",
        "        regressor.fit(X, y)\n",
        "        return regressor\n",
        "\n",
        "    def predict_location(self, regressor, locations):\n",
        "        predicted_prices = {loc: regressor.predict([[loc]])[0] for loc in locations}\n",
        "        best_location = min(predicted_prices, key=predicted_prices.get)\n",
        "        return self.label_encoder.inverse_transform([best_location])[0]\n",
        "\n",
        "    def suggest_location(self, crop_type):\n",
        "        if not self.load_data():\n",
        "            return \"Error: Unable to load data.\"\n",
        "        if not self.prepare_data():\n",
        "            return \"Error: Unable to prepare data.\"\n",
        "        filtered_data = self.filter_data(crop_type)\n",
        "        if filtered_data.empty:\n",
        "            return \"No data available for the given crop type.\"\n",
        "        X = filtered_data[['location']]\n",
        "        y = filtered_data['labourprice']\n",
        "        regressor = self.train_model(X, y)\n",
        "        locations = filtered_data['location'].unique()\n",
        "        best_location = self.predict_location(regressor, locations)\n",
        "        return best_location\n",
        "\n",
        "# Example usage:\n",
        "csv_file = \"crop_data.csv\"\n",
        "suggester = CropLocationSuggester(csv_file)\n",
        "\n",
        "# Example: Suggest location for Rice\n",
        "crop_type = \"Rice\"\n",
        "best_location = suggester.suggest_location(crop_type)\n",
        "print(f\"The best location for {crop_type} is: {best_location}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDjX8kwd1u1h",
        "outputId": "44ed8a79-9fe3-4632-c54a-b761d078631a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best location for Rice is: No data available for the given crop type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "# Function to generate random locations in India\n",
        "def generate_random_location():\n",
        "    locations = [\"Rajasthan\", \"Uttar Pradesh\", \"Punjab\", \"Madhya Pradesh\", \"Haryana\"]\n",
        "    return random.choice(locations)\n",
        "\n",
        "# Function to generate random crop types\n",
        "def generate_random_crop_type():\n",
        "    crop_types = [\"Wheat\", \"Rice\", \"Cotton\", \"Soybean\", \"Mustard\", \"Sugarcane\", \"Maize\", \"Barley\", \"Lentils\", \"Millet\"]\n",
        "    return random.choice(crop_types)\n",
        "\n",
        "# Function to generate random prices\n",
        "def generate_random_price():\n",
        "    return random.randint(400, 800)\n",
        "\n",
        "# Function to generate random wages\n",
        "def generate_random_wages():\n",
        "    return random.randint(800, 1200)\n",
        "\n",
        "# Function to generate random distances\n",
        "def generate_random_distance():\n",
        "    return random.randint(100, 500)\n",
        "\n",
        "# Function to generate random travel times\n",
        "def generate_random_travel_time():\n",
        "    return random.randint(3, 8)\n",
        "\n",
        "# Generate Farm Laborers Data\n",
        "with open('farm_laborers_data.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['ID', 'Location', 'Preferred_Work_Location']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for i in range(1, 101):\n",
        "        writer.writerow({'ID': i, 'Location': generate_random_location(), 'Preferred_Work_Location': generate_random_location()})\n",
        "\n",
        "# Generate Crop Season Data\n",
        "with open('crop_season_data.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['Crop_Type', 'Location', 'Expected_Price']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for i in range(1, 200):\n",
        "        writer.writerow({'Crop_Type': generate_random_crop_type(), 'Location': generate_random_location(), 'Expected_Price': generate_random_price()})\n",
        "\n",
        "# Generate Job Opportunities Data\n",
        "with open('job_opportunities_data.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['Job_ID', 'Crop_Type', 'Location', 'Wages']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for i in range(1, 101):\n",
        "        writer.writerow({'Job_ID': i, 'Crop_Type': generate_random_crop_type(), 'Location': generate_random_location(), 'Wages': generate_random_wages()})\n",
        "\n",
        "# Generate Price Data\n",
        "with open('price_data.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['Crop_Type', 'Location', 'Price']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for i in range(1, 101):\n",
        "        writer.writerow({'Crop_Type': generate_random_crop_type(), 'Location': generate_random_location(), 'Price': generate_random_price()})\n",
        "\n",
        "# Generate Migration Routes Data\n",
        "with open('migration_routes_data.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['From_Location', 'To_Location', 'Distance', 'Travel_Time']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for i in range(1, 101):\n",
        "        writer.writerow({'From_Location': generate_random_location(), 'To_Location': generate_random_location(), 'Distance': generate_random_distance(), 'Travel_Time': generate_random_travel_time()})\n"
      ],
      "metadata": {
        "id": "R6D-l1dh8tyi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data from CSV files\n",
        "farm_laborers_data = pd.read_csv('farm_laborers_data.csv')\n",
        "job_opportunities_data = pd.read_csv('job_opportunities_data.csv')\n",
        "price_data = pd.read_csv('price_data.csv')\n",
        "\n",
        "# Define array of crop types\n",
        "crop_types = ['Wheat', 'Rice', 'Cotton', 'Soybean']\n",
        "\n",
        "# Iterate through each crop type\n",
        "for selected_crop_type in crop_types:\n",
        "    print(f\"Processing crop type: {selected_crop_type}\")\n",
        "    print(\"----------------------------------------\")\n",
        "\n",
        "    # Filter job opportunities data for selected crop type\n",
        "    filtered_job_opportunities = job_opportunities_data[job_opportunities_data['Crop_Type'] == selected_crop_type]\n",
        "\n",
        "    # Calculate weighted scores\n",
        "    grouped_job_opportunities = filtered_job_opportunities.groupby('Location')\n",
        "    average_wages = grouped_job_opportunities['Wages'].mean()\n",
        "    average_prices = price_data[price_data['Crop_Type'] == selected_crop_type].groupby('Location')['Price'].mean()\n",
        "\n",
        "    # Drop locations with NaN values in either average wages or average prices\n",
        "    weighted_scores = (0.7 * average_wages) + (0.3 * average_prices)\n",
        "    weighted_scores = weighted_scores.dropna()\n",
        "\n",
        "    # Recommend the location with the highest weighted score\n",
        "    if not weighted_scores.empty:\n",
        "        best_location = weighted_scores.idxmax()\n",
        "        print(f\"The best location for {selected_crop_type} is: {best_location}\")\n",
        "    else:\n",
        "        print(f\"No data available for {selected_crop_type}.\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVaNIHbv8wiH",
        "outputId": "8e358296-38bb-4e3e-9c7c-4bad28fc02d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing crop type: Wheat\n",
            "----------------------------------------\n",
            "The best location for Wheat is: Punjab\n",
            "\n",
            "Processing crop type: Rice\n",
            "----------------------------------------\n",
            "The best location for Rice is: Madhya Pradesh\n",
            "\n",
            "Processing crop type: Cotton\n",
            "----------------------------------------\n",
            "The best location for Cotton is: Uttar Pradesh\n",
            "\n",
            "Processing crop type: Soybean\n",
            "----------------------------------------\n",
            "The best location for Soybean is: Uttar Pradesh\n",
            "\n"
          ]
        }
      ]
    }
  ]
}